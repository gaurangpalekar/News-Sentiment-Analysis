{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from nsepython import *\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/shubham/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis libraries\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.niftyindices.com/IndexConstituent/ind_nifty50list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39m'\u001b[39;49m\u001b[39mhttps://in.investing.com/indices/s-p-cnx-nifty-components\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1207\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1208\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1209\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1222\u001b[0m )\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[1;32m    987\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[1;32m    988\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs)\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/html.py:821\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 821\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    822\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(r, \u001b[39m\"\u001b[39m\u001b[39mtext_content\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/html.py:802\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     \u001b[39mif\u001b[39;00m is_url(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio):\n\u001b[0;32m--> 802\u001b[0m         \u001b[39mwith\u001b[39;00m urlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mio) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    803\u001b[0m             r \u001b[39m=\u001b[39m parse(f, parser\u001b[39m=\u001b[39mparser)\n\u001b[1;32m    804\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m         \u001b[39m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "csv = pd.read_html('https://in.investing.com/indices/s-p-cnx-nifty-components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#NIFTY URLS\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nifty_500_ticker_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.niftyindices.com/IndexConstituent/ind_nifty500list.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m nifty_500 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(nifty_500_ticker_url)\n\u001b[1;32m      4\u001b[0m nifty_500\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./datasets/NIFTY_500.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m nifty_200_ticker_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.niftyindices.com/IndexConstituent/ind_nifty200list.csv\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    712\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    714\u001b[0m     path_or_buf,\n\u001b[1;32m    715\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    716\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    717\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    718\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    719\u001b[0m )\n\u001b[1;32m    721\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    722\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    362\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[0;32m--> 363\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[1;32m    364\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    366\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/Nifty-500-Live-Sentiment-Analysis/.venv/lib/python3.11/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     h\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#NIFTY URLS\n",
    "nifty_500_ticker_url = 'https://www.niftyindices.com/IndexConstituent/ind_nifty500list.csv'\n",
    "nifty_500 = pd.read_csv(nifty_500_ticker_url)\n",
    "nifty_500.to_csv('./datasets/NIFTY_500.csv')\n",
    "nifty_200_ticker_url = 'https://www.niftyindices.com/IndexConstituent/ind_nifty200list.csv'\n",
    "nifty_200 = pd.read_csv(nifty_200_ticker_url)\n",
    "nifty_200.to_csv('./datasets/NIFTY_200.csv')\n",
    "nifty_100_ticker_url = 'https://www.niftyindices.com/IndexConstituent/ind_nifty100list.csv'\n",
    "nifty_100 = pd.read_csv(nifty_100_ticker_url)\n",
    "nifty_100.to_csv('./datasets/NIFTY_100.csv')\n",
    "nifty_50_ticker_url = 'https://www.niftyindices.com/IndexConstituent/ind_nifty50list.csv'\n",
    "nifty_50 = pd.read_csv(nifty_50_ticker_url)\n",
    "nifty_50.to_csv('./datasets/NIFTY_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set universe\n",
    "universe = nifty_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV & create a tickers df\n",
    "tickers_df = universe[['Symbol', 'Company Name']]\n",
    "tickers_list = tickers_df['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News URL\n",
    "news_url = 'https://ticker.finology.in/company/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all available data\n",
    "article_data = pd.read_csv('./NIFTY_500_Articles.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# list to store article data\n",
    "article_data = []\n",
    "# list to store tickers for which data is unavailable\n",
    "unavailable_tickers = []\n",
    "# length of companies\n",
    "companies_len = len(tickers_list)\n",
    "tickers_length = companies_len\n",
    "#days_limit = datetime.datetime.now() - datetime.timedelta(days=30) #only 30 days old or newer articles\n",
    "print('Fetching Article data..')\n",
    "for i,ticker in enumerate(tickers_list):\n",
    "    print(i, ticker)\n",
    "    url= '{}/{}'.format(news_url, ticker)\n",
    "    header={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}\n",
    "    response = requests.get(url, headers=header)\n",
    "    html = BeautifulSoup(response.content, 'lxml')\n",
    "    news_links = html.select('#newsarticles > a')\n",
    "    if len(news_links) == 0:\n",
    "        print('No news found for {}'.format(ticker))\n",
    "        unavailable_tickers.append(ticker)\n",
    "        continue\n",
    "    # for tickers which are not recognized by finology website, it returns home-page. There's also a news section on homepage. so for unrecognized tickers, this function will scrape general financial news instead of ticker specific news\n",
    "    # var to store article count\n",
    "    ticker_articles_counter = 0\n",
    "    for link in news_links:\n",
    "        art_title = link.find('span', class_='h6').text\n",
    "        #separate date and time from datetime object\n",
    "        date_time_obj = datetime.strptime(link.find('small').text, '%d %b %Y, %I:%M%p')\n",
    "        #if (date_time_obj <= days_limit):\n",
    "        #     continue\n",
    "        art_date = date_time_obj.date().strftime('%Y/%m/%d')\n",
    "        art_time = date_time_obj.time().strftime('%H:%M')\n",
    "        article_data.append([ticker, art_title, art_date, art_time])\n",
    "        ticker_articles_counter += 1\n",
    "    print('No of articles for {} is {}'.format(ticker, ticker_articles_counter))\n",
    "    if(ticker_articles_counter==0):\n",
    "        print('{} added to unavailable list')\n",
    "        unavailable_tickers.append(ticker)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the loop again, but for the tickers for which news could not be fetched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df from the news articles list\n",
    "articles_df = pd.DataFrame(article_data, columns=['Ticker', 'Headline', 'Date', 'Time'])\n",
    "articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tickers for which news was fetched\n",
    "tickers_list = articles_df['Ticker'].unique()\n",
    "tickers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update original tickers_df to remove tickers for which news was not available\n",
    "tickers_df = tickers_df[tickers_df['Symbol'].isin(tickers_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(article_data['Ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis libraries\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_scores_df = pd.DataFrame(articles_df['Headline'].apply(vader.polarity_scores).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with article details and scores merged.\n",
    "art_scores_df = pd.merge(articles_df, art_scores_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#art_scores_df.to_csv('NIFTY_500_Articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_metadata = pd.read_csv('./ticker_metadata.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Get Company,Sector,Industry,mCap Data\n",
    "ticker_meta = []\n",
    "new_length = len(tickers_list)\n",
    "#new_length = 10\n",
    "print('Fetching ticker meta data')\n",
    "# whether to get only data available in tickers_list or the whole universe bc even if we take whole universe, we will later merge the dfs ticker_meta and art_scores_df\n",
    "# but since we're planning on not to fetch industry and sector data that often, its better to take the universe meta\n",
    "\n",
    "for i, ticker in enumerate(tickers_list):\n",
    "    meta = nse_eq(ticker)\n",
    "    print(i, ticker)\n",
    "    try:\n",
    "        sector = meta['industryInfo']['macro']\n",
    "    except KeyError:\n",
    "        print('{} sector info is not available'.format(ticker))\n",
    "        sector = np.nan\n",
    "        industry = np.nan\n",
    "        mCap = np.nan\n",
    "        companyName = np.nan\n",
    "        ticker_meta.append([ticker, sector, industry, mCap, companyName])\n",
    "        continue\n",
    "    try:\n",
    "        industry = meta['industryInfo']['industry']\n",
    "    except KeyError:\n",
    "        print('{} industry info is not available'.format(ticker))\n",
    "        industry = np.nan\n",
    "        mCap = np.nan\n",
    "        companyName = np.nan\n",
    "        ticker_meta.append([ticker, sector, industry, mCap, companyName])\n",
    "        continue\n",
    "    try:\n",
    "        mCap = round((meta['priceInfo']['previousClose'] * meta['securityInfo']['issuedSize'])/1000000000, 2)\n",
    "    except KeyError:\n",
    "        print('{} mCap data is not available'.format(ticker))\n",
    "        mCap = np.nan\n",
    "        companyName = np.nan\n",
    "        ticker_meta.append([ticker, sector, industry, mCap, companyName])\n",
    "        continue\n",
    "    try:\n",
    "        companyName = meta['info']['companyName']\n",
    "    except KeyError:\n",
    "        print('{} company Name is not available'.format(ticker))\n",
    "        companyName = np.nan\n",
    "        ticker_meta.append([ticker, sector, industry, mCap, companyName])\n",
    "    ticker_meta.append([ticker, sector, industry, mCap, companyName])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_indices = pd.read_csv('XC-tickers.csv')\n",
    "xc_indices.columns = ['Ticker', 'XC-Sector', 'XC-Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_meta_df = pd.DataFrame(ticker_meta, columns=['Ticker', 'Sector', 'Industry', 'Market Cap', 'Company Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_metadata = pd.merge(ticker_meta_df, xc_indices, on='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticker_metadata.to_csv('ticker_matadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_metadata.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = article_data.drop(['Unnamed: 0'], axis=1)\n",
    "ticker_metadata = ticker_metadata.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_score_summary = article_data.groupby('Ticker').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_score_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(article_score_summary, ticker_metadata,  on='Ticker', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_scores = article_data.groupby('Ticker').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(ticker_metadata, ticker_scores, on='Ticker', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = ['Symbol','Macro-Sector','Industry', 'Market Cap (Billion Rs)','Company Name','XC-Sector', 'XC-Industry', 'Negative', 'Neutral', 'Positive', 'Sentiment Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating Plots')\n",
    "fig = px.treemap(\n",
    "    final_df, path=[px.Constant('Nifty 500'), 'XC-Sector', 'XC-Industry', 'Symbol'], values='Market Cap (Billion Rs)', color='Sentiment Score',\n",
    "    hover_data=['Company Name', 'Negative', 'Neutral', 'Positive', 'Sentiment Score'], color_continuous_scale=['#FF0000', \"#000000\", '#00FF00'], color_continuous_midpoint=0\n",
    "    )\n",
    "fig.data[0].customdata = final_df[['Company Name', 'Negative', 'Neutral', 'Positive', 'Sentiment Score']]\n",
    "fig.data[0].texttemplate = \"%{label}<br>%{customdata[4]}\"\n",
    "fig.update_traces(textposition=\"middle center\")\n",
    "fig.update_layout(margin = dict(t=30, l=10, r=10, b=10), font_size=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tickers = ['3MINDIA', 'APLAPOLLO', 'ABBOTINDIA', 'ABSLAMC', 'ALKYLAMINE', 'AMARAJABAT', 'AMBER', 'APOLLOTYRE', 'APTUS', 'ASTRAZEN', 'BEML', 'BAJAJELEC', 'BALKRISIND', 'BATAINDIA', 'BAYERCROP', 'BERGEPAINT', 'BHARATRAS', 'BLUEDART', 'BRITANNIA', 'MAPMYINDIA', 'CESC', 'CAMPUS', 'CEATLTD', 'CDSL', 'CENTURYPLY', 'CHOLAHLDNG', 'COLPAL', 'CUMMINSIND', 'DEVYANI', 'DIVISLAB', 'DIXON', 'EIHOTEL', 'EPL', 'EMAMILTD', 'NYKAA', 'FACT', 'FINEORG', 'GAIL', 'GICRE', 'GODFRYPHLP', 'GUJALKALI', 'GUJGASLTD', 'GSPL', 'HLEGLAS', 'HIKAL', 'HGS', 'HAL', 'HONAUT', 'HUDCO', 'IFBIND', 'INDIACEM', 'IBULHSGFIN', 'IRFC', 'IGL', 'IPCALAB', 'JBCHEPHARM', 'KNRCON', 'KPITTECH', 'KANSAINER', 'L&TFH', 'LAXMIMACH', 'LUXIND', 'MRF', 'MGL', 'M&MFIN', 'M&M', 'MAHLOG', 'MAZDOCK', 'MEDPLUS', 'METROPOLIS', 'MSUMI', 'MUTHOOTFIN', 'NLCINDIA', 'NATIONALUM', 'NAVINFLUOR', 'NESTLEIND', 'NAM-INDIA', 'NUVOCO', 'OBEROIRLTY', 'OIL', 'OLECTRA', 'PCBL', 'PATANJALI', 'PFIZER', 'POLYPLEX', 'PFC', 'PRESTIGE', 'PRINCEPIPE', 'PGHL', 'RAIN', 'RAINBOW', 'RATNAMANI', 'REDINGTON', 'RBA', 'SIS', 'SRF', 'SHILPAMED', 'SAIL', 'SUMICHEM', 'SUNTV', 'SUNDARMFIN', 'SUPREMEIND', 'SYMPHONY', 'TCNSBRANDS', 'TTML', 'TEJASNET', 'THERMAX', 'THYROCARE', 'TORNTPHARM', 'TIINDIA', 'UPL', 'UTIAMC', 'VIPIND', 'VAIBHAVGBL', 'VBL', 'MANYAVAR', 'VIJAYA', 'VOLTAS', 'WHIRLPOOL', 'WOCKPHARMA', 'ZFCVINDIA', 'ZEEL', 'ZENSARTECH', 'ZOMATO', 'ECLERX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url = 'https://ticker.finology.in/company/'\n",
    "# list to store article data\n",
    "article_data = []\n",
    "unavailable_tickers = []\n",
    "# list to store tickers for which data is unavailable\n",
    "# length of companies\n",
    "companies_len = len(test_tickers)\n",
    "tickers_length = companies_len\n",
    "#days_limit = datetime.datetime.now() - datetime.timedelta(days=30) #only 30 days old or newer articles\n",
    "print('Fetching Article data..')\n",
    "for i in range(tickers_length):\n",
    "    print(i, test_tickers[i])\n",
    "    url= '{}/{}'.format(news_url, test_tickers[i])\n",
    "    header={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}\n",
    "    response = requests.get(url, headers=header)\n",
    "    html = BeautifulSoup(response.content, 'lxml')\n",
    "    news_links = html.select('#newsarticles > a')\n",
    "    if len(news_links) == 0:\n",
    "        print('No news found for {}'.format(test_tickers[i]))\n",
    "        unavailable_tickers.append(test_tickers[i])\n",
    "        continue\n",
    "    # for tickers which are not recognized by finology website, it returns home-page. There's also a news section on homepage. so for unrecognized tickers, this function will scrape general financial news instead of ticker specific news\n",
    "    # var to store article count\n",
    "    ticker_articles_counter = 0\n",
    "    for link in news_links:\n",
    "        art_title = link.find('span', class_='h6').text\n",
    "        #separate date and time from datetime object\n",
    "        date_time_obj = datetime.datetime.strptime(link.find('small').text, '%d %b %Y, %I:%M%p')\n",
    "        #if (date_time_obj <= days_limit):\n",
    "        #     continue\n",
    "        art_date = date_time_obj.date().strftime('%Y/%m/%d')\n",
    "        art_time = date_time_obj.time().strftime('%H:%M')\n",
    "        article_data.append([test_tickers[i], art_title, art_date, art_time])\n",
    "        ticker_articles_counter += 1\n",
    "    if(ticker_articles_counter==0):\n",
    "        print('Article length = 0 for {}'.format(test_tickers[i]))\n",
    "        unavailable_tickers.append(tickers_list[i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(article_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://ticker.finology.in/company/EMAMILTD'\n",
    "header={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}\n",
    "response = requests.get(url, headers=header)\n",
    "html = BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_links = html.select('#newsarticles > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "236178af6f648e00519e077836b3ac634bd3def9b921796a679cc929c64b686e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
